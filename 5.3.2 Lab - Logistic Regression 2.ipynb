{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fe8d27da-75df-4cfd-bae1-4676f0ba1111"}}},{"cell_type":"markdown","source":["# Logistic Regression Lab 2\n\n**Objectives**:\n1. Perform a train-test split on data.\n1. Evaluate four multi-variable logistic regression models using accuracy\nand a confusion matrix.\n\nAdditionally, you will be asked to consider overfitting and underfitting\nof the models based upon these results."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f5e7990b-f35d-4065-8bed-c19627439e3f"}}},{"cell_type":"code","source":["%run ../../Includes/Classroom-Setup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8d992965-86ba-4666-8b91-ac0d85283ea3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Mounting course-specific datasets to <b>/mnt/training</b>...</br>Datasets are already mounted to <b>/mnt/training</b> from <b>s3a://databricks-corp-training/common</b>","textData":null,"removedWidgets":[],"addedWidgets":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["Mounting course-specific datasets to <b>/mnt/training</b>...</br>Datasets are already mounted to <b>/mnt/training</b> from <b>s3a://databricks-corp-training/common</b>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[2]: DataFrame[]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[2]: DataFrame[]</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">res1: Boolean = false\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">res1: Boolean = false\n</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">res2: Boolean = false\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">res2: Boolean = false\n</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Setup\n\n### Load the Data\nThe `Includes/Classroom-Setup` notebook has made an aggregate table of data\navailable to us via the Metastore associated with our workspace. We can load\nthe data as a pandas dataframe using the cell below.\n\nThis command loads the table using the Metastore reference. The `.toPandas()`\nmethod converts the Spark DataFrame to a Pandas DataFrame. We will use the\nPandas DataFrame with Scikit-Learn throughout this Module."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"53dddf8c-a925-4ff5-b79e-f3e552badd7b"}}},{"cell_type":"code","source":["ht_agg_spark_df = spark.read.table(\"ht_agg\")\nht_agg_pandas_df = ht_agg_spark_df.toPandas()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"90608e85-c5e1-4ea2-94b7-faae3406ae6e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Prepare Four Datasets and Target\n\nNext, we will prepare four subsets of our, used as in the previous lab\nto build four different logistic regression models.\n\nWe also prepare our target vector, `y`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"88367d62-5327-4fa3-9443-189b37656d9f"}}},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n\nX_1 = ht_agg_pandas_df[['mean_active_heartrate', 'mean_resting_heartrate']]\nX_2 = ht_agg_pandas_df[['mean_active_heartrate', 'mean_vo2']]\nX_3 = ht_agg_pandas_df[['mean_active_heartrate', 'mean_bmi', 'mean_vo2']]\nX_4 = ht_agg_pandas_df[['mean_active_heartrate', 'mean_bmi', 'mean_vo2', 'mean_resting_heartrate']]\n\nle = LabelEncoder()\nlifestyle = ht_agg_pandas_df['lifestyle']\nle.fit(lifestyle)\ny = le.transform(lifestyle)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cb59d680-b565-431f-b581-d9320203caac"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Framing a Business Problem\n\nOver the next few labs, we will use supervised machine learning\nto answer a new business question:\n\n> Given a users fitness profile, can we predict the lifestyle of a user?\n\nLike the regression problem we previously solved,\nour **inputs** will be fitness profile information. This is, however, a classification\nproblem and will have a different **output**, lifestyle."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dfaac593-4a82-4713-8e00-1606f1e8a500"}}},{"cell_type":"markdown","source":["### Perform the Train-Test Split\n\nNext, we will split one of our four subsets of feature data and our target data\ninto training and testing data."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7d72c6d2-ebe0-4b6a-a841-bd9f5bb0c3d0"}}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n\nX_1_train, X_1_test, y_train, y_test = train_test_split(X_1, y)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"40fbcf5a-3765-4600-a515-f598a0d64be9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Your Turn\n\n### Exercise 1: Perform the Train-Test Split\n\nPerform the train-test split on the remaining data subsets:\n1. use the helper function `train_test_split`\n1. split the following subsets:\n   - `X_2`, `X_3`, `X_4`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4a851fac-b373-4afa-92e7-b1138f1b79a0"}}},{"cell_type":"code","source":["# ANSWER\nX_2_train, X_2_test, y_train, y_test = train_test_split(X_2, y)\nX_3_train, X_3_test, y_train, y_test = train_test_split(X_3, y)\nX_4_train, X_4_test, y_train, y_test = train_test_split(X_4, y)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"08b2dbe0-e52c-46e6-8298-219473d1ec56"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Exercise 2: Multi-Variable Logistic Regression\n\nFit four multiple-variable logistic models, one for each datasubset."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ff3eb381-544f-4af2-97d6-a94353fd5e26"}}},{"cell_type":"code","source":["# ANSWER\nfrom sklearn.linear_model import LogisticRegression\nlr_1 = LogisticRegression(max_iter=10000)\nlr_2 = LogisticRegression(max_iter=10000)\nlr_3 = LogisticRegression(max_iter=10000)\nlr_4 = LogisticRegression(max_iter=10000)\n\nlr_1.fit(X_1_train, y_train)\nlr_2.fit(X_2_train, y_train)\nlr_3.fit(X_3_train, y_train)\nlr_4.fit(X_4_train, y_train)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8568f813-fc7e-4170-8bbe-070aa7d2fdfb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[11]: LogisticRegression(max_iter=10000)</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[11]: LogisticRegression(max_iter=10000)</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Demonstration\n### Evaluate a Multi-variable Model using accuracy and a confusion matrix\n\nFinally, we evaulate our models. We do so using the accuracy metric and a confusion matrix.\n\nTo use these metrics, we need to\n1. generate a vector of precictions using `estimator.predict()`\n1. pass actual and predicted values to the metric as `metric(actual, predicted)`\n1. do this for both the training and testing data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b12dce25-0692-4475-bb3f-9057f6afe39e"}}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, confusion_matrix\n\ny_train_1_predicted = lr_1.predict(X_1_train)\ny_test_1_predicted = lr_1.predict(X_1_test)\n\nprint(\"training accuracy: \", accuracy_score(y_train, y_train_1_predicted))\nprint(\"test accuracy:     \", accuracy_score(y_test, y_test_1_predicted))\nprint(\"training confusion matrix\")\nprint(confusion_matrix(y_train, y_train_1_predicted))\nprint(\"\")\nprint(\"test confusion matrix\")\nprint(confusion_matrix(y_test, y_test_1_predicted))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"82b68ff1-5651-4b06-b292-19d5dd20c7c5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">training accuracy:  0.3622222222222222\ntest accuracy:      0.332\ntraining confusion matrix\n[[  0 628   0   0]\n [  0 815   0   0]\n [  0 228   0   0]\n [  0 579   0   0]]\n\ntest confusion matrix\n[[  0 231   0   0]\n [  0 249   0   0]\n [  0  84   0   0]\n [  0 186   0   0]]\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">training accuracy:  0.3622222222222222\ntest accuracy:      0.332\ntraining confusion matrix\n[[  0 628   0   0]\n [  0 815   0   0]\n [  0 228   0   0]\n [  0 579   0   0]]\n\ntest confusion matrix\n[[  0 231   0   0]\n [  0 249   0   0]\n [  0  84   0   0]\n [  0 186   0   0]]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Question**: What do you notice about the results?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c9419e62-97a6-4194-bff9-70ecd16da288"}}},{"cell_type":"markdown","source":["## Your Turn\n### Exercise 3: Generate Predictions\n1. use the following subset splits:\n   - `X_1_test`, `X_2_test`, `X_3_test`, `X_4_test`\n   - `X_1_train`, `X_2_train`, `X_3_train`, `X_4_train`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"24cb2d28-14ad-4f0a-b038-69d08f3868eb"}}},{"cell_type":"code","source":["# ANSWER\ny_train_1_predicted = lr_1.predict(X_1_train)\ny_test_1_predicted = lr_1.predict(X_1_test)\ny_train_2_predicted = lr_2.predict(X_2_train)\ny_test_2_predicted = lr_2.predict(X_2_test)\ny_train_3_predicted = lr_3.predict(X_3_train)\ny_test_3_predicted = lr_3.predict(X_3_test)\ny_train_4_predicted = lr_4.predict(X_4_train)\ny_test_4_predicted = lr_4.predict(X_4_test)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"94dd700d-c873-480f-b2fb-ece8170417ee"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Exercise 4: Evaluate Our Models\n\n1. Use the `accuracy_score` and `confusion_matrix` metrics\n1. don't forget to take the square root of the mean squared error\n1. use the following subset splits:\n   - `X_2_test`, `X_3_test`, `X_4_test`\n   - `X_2_train`, `X_3_train`, `X_4_train`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c6d924a7-7004-4e1a-af89-f1633f22ed4b"}}},{"cell_type":"code","source":["# ANSWER\ntrain_1_accuracy = accuracy_score(y_train, y_train_1_predicted)\ntrain_1_conf_mat = confusion_matrix(y_train, y_train_1_predicted)\ntest_1_accuracy = accuracy_score(y_test, y_test_1_predicted)\ntest_1_conf_mat = confusion_matrix(y_test, y_test_1_predicted)\n\ntrain_2_accuracy = accuracy_score(y_train, y_train_2_predicted)\ntrain_2_conf_mat = confusion_matrix(y_train, y_train_2_predicted)\ntest_2_accuracy = accuracy_score(y_test, y_test_2_predicted)\ntest_2_conf_mat = confusion_matrix(y_test, y_test_2_predicted)\n\ntrain_3_accuracy = accuracy_score(y_train, y_train_3_predicted)\ntrain_3_conf_mat = confusion_matrix(y_train, y_train_3_predicted)\ntest_3_accuracy = accuracy_score(y_test, y_test_3_predicted)\ntest_3_conf_mat = confusion_matrix(y_test, y_test_3_predicted)\n\ntrain_4_accuracy = accuracy_score(y_train, y_train_4_predicted)\ntrain_4_conf_mat = confusion_matrix(y_train, y_train_4_predicted)\ntest_4_accuracy = accuracy_score(y_test, y_test_4_predicted)\ntest_4_conf_mat = confusion_matrix(y_test, y_test_4_predicted)\n\nprint(\"model 1: training accuracy: \", train_1_accuracy)\nprint(\"model 1: training confusion matrix: \")\nprint(train_1_conf_mat)\nprint(\" \")\nprint(\"model 1: test accuracy:     \", test_1_accuracy)\nprint(\"model 1: test confusion matrix:     \")\nprint(test_1_conf_mat)\nprint(\" \")\nprint(\"model 2: training accuracy: \", train_2_accuracy)\nprint(\"model 2: training confusion matrix: \")\nprint(train_2_conf_mat)\nprint(\" \")\nprint(\"model 2: test accuracy:     \", test_2_accuracy)\nprint(\"model 2: test confusion matrix:     \")\nprint(test_2_conf_mat)\nprint(\" \")\nprint(\"model 3: training accuracy: \", train_3_accuracy)\nprint(\"model 3: training confusion matrix: \")\nprint(train_3_conf_mat)\nprint(\" \")\nprint(\"model 3: test accuracy:     \", test_3_accuracy)\nprint(\"model 3: test confusion matrix:     \")\nprint(test_3_conf_mat)\nprint(\" \")\nprint(\"model 4: training accuracy: \", train_4_accuracy)\nprint(\"model 4: training confusion matrix: \")\nprint(train_4_conf_mat)\nprint(\" \")\nprint(\"model 4: test accuracy:     \", test_4_accuracy)\nprint(\"model 4: test confusion matrix:     \")\nprint(test_4_conf_mat)\nprint(\" \")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c6831c71-4056-4c2e-acbd-3d83323c3a09"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">model 1: training accuracy:  0.3622222222222222\nmodel 1: training confusion matrix: \n[[  0 628   0   0]\n [  0 815   0   0]\n [  0 228   0   0]\n [  0 579   0   0]]\n \nmodel 1: test accuracy:      0.332\nmodel 1: test confusion matrix:     \n[[  0 231   0   0]\n [  0 249   0   0]\n [  0  84   0   0]\n [  0 186   0   0]]\n \nmodel 2: training accuracy:  0.3622222222222222\nmodel 2: training confusion matrix: \n[[  0 628   0   0]\n [  0 815   0   0]\n [  0 228   0   0]\n [  0 579   0   0]]\n \nmodel 2: test accuracy:      0.332\nmodel 2: test confusion matrix:     \n[[  0 231   0   0]\n [  0 249   0   0]\n [  0  84   0   0]\n [  0 186   0   0]]\n \nmodel 3: training accuracy:  0.36177777777777775\nmodel 3: training confusion matrix: \n[[  1 627   0   0]\n [  2 813   0   0]\n [  3 225   0   0]\n [  2 577   0   0]]\n \nmodel 3: test accuracy:      0.332\nmodel 3: test confusion matrix:     \n[[  0 231   0   0]\n [  0 249   0   0]\n [  1  83   0   0]\n [  0 186   0   0]]\n \nmodel 4: training accuracy:  0.6124444444444445\nmodel 4: training confusion matrix: \n[[294 240   0  94]\n [166 649   0   0]\n [  0   0  56 172]\n [143   8  49 379]]\n \nmodel 4: test accuracy:      0.6\nmodel 4: test confusion matrix:     \n[[110  85   0  36]\n [ 47 202   0   0]\n [  2   0  20  62]\n [ 49   3  16 118]]\n \n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">model 1: training accuracy:  0.3622222222222222\nmodel 1: training confusion matrix: \n[[  0 628   0   0]\n [  0 815   0   0]\n [  0 228   0   0]\n [  0 579   0   0]]\n \nmodel 1: test accuracy:      0.332\nmodel 1: test confusion matrix:     \n[[  0 231   0   0]\n [  0 249   0   0]\n [  0  84   0   0]\n [  0 186   0   0]]\n \nmodel 2: training accuracy:  0.3622222222222222\nmodel 2: training confusion matrix: \n[[  0 628   0   0]\n [  0 815   0   0]\n [  0 228   0   0]\n [  0 579   0   0]]\n \nmodel 2: test accuracy:      0.332\nmodel 2: test confusion matrix:     \n[[  0 231   0   0]\n [  0 249   0   0]\n [  0  84   0   0]\n [  0 186   0   0]]\n \nmodel 3: training accuracy:  0.36177777777777775\nmodel 3: training confusion matrix: \n[[  1 627   0   0]\n [  2 813   0   0]\n [  3 225   0   0]\n [  2 577   0   0]]\n \nmodel 3: test accuracy:      0.332\nmodel 3: test confusion matrix:     \n[[  0 231   0   0]\n [  0 249   0   0]\n [  1  83   0   0]\n [  0 186   0   0]]\n \nmodel 4: training accuracy:  0.6124444444444445\nmodel 4: training confusion matrix: \n[[294 240   0  94]\n [166 649   0   0]\n [  0   0  56 172]\n [143   8  49 379]]\n \nmodel 4: test accuracy:      0.6\nmodel 4: test confusion matrix:     \n[[110  85   0  36]\n [ 47 202   0   0]\n [  2   0  20  62]\n [ 49   3  16 118]]\n \n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Question**: Which of these models is the best at predicting lifestyle?\n\n**Question**: Do any of the models show signs of overfitting?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"661bce2c-c250-40f1-a494-7b1b230d35c4"}}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2021 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9697b719-4082-44c2-9419-5a8957775d11"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"5.3.2 Lab - Logistic Regression 2","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3165647092658822}},"nbformat":4,"nbformat_minor":0}
