{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"567685e7-0e39-4735-a90a-104075bb75e0"}}},{"cell_type":"markdown","source":["# Decision Tree Lab\n\n**Objective**:\n1. Perform a train-test split on data.\n1. Evaluate four multi-variable decision tree models using accuracy\nand a confusion matrix.\n\nAdditionally, you will be asked to consider overfitting and underfitting\nof the models based upon these results."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fc45489f-3dbb-4b05-9825-de070388373b"}}},{"cell_type":"code","source":["%run ../../Includes/Classroom-Setup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fd6bc82b-397e-4c30-8ca1-a8a68bc3ea7b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Mounting course-specific datasets to <b>/mnt/training</b>...</br>Datasets are already mounted to <b>/mnt/training</b> from <b>s3a://databricks-corp-training/common</b>","textData":null,"removedWidgets":[],"addedWidgets":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["Mounting course-specific datasets to <b>/mnt/training</b>...</br>Datasets are already mounted to <b>/mnt/training</b> from <b>s3a://databricks-corp-training/common</b>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[2]: DataFrame[]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[2]: DataFrame[]</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">res1: Boolean = false\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">res1: Boolean = false\n</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">res2: Boolean = false\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">res2: Boolean = false\n</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Setup\n\n### Load the Data\nThe `Includes/Classroom-Setup` notebook has made an aggregate table of data\navailable to us via the Metastore associated with our workspace. We can load\nthe data as a pandas dataframe using the cell below.\n\nThis command loads the table using the Metastore reference. The `.toPandas()`\nmethod converts the Spark DataFrame to a Pandas DataFrame. We will use the\nPandas DataFrame with Scikit-Learn throughout this Module."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8c1778bf-d570-4f1c-a4cb-6a07398375c6"}}},{"cell_type":"code","source":["ht_agg_spark_df = spark.read.table(\"ht_agg\")\nht_agg_pandas_df = ht_agg_spark_df.toPandas()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a6f43d8c-9bba-4004-8514-7ecad0d45010"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Prepare Four Datasets and Target\n\nNext, we will prepare four subsets of our, used as in the previous lab\nto build four different decision tree models.\n\nWe also prepare our target vector, `y`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5f0d5d2e-9012-4c72-9c95-da8917709a9a"}}},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n\nX_1 = ht_agg_pandas_df[['mean_active_heartrate', 'mean_resting_heartrate']]\nX_2 = ht_agg_pandas_df[['mean_active_heartrate', 'mean_vo2']]\nX_3 = ht_agg_pandas_df[['mean_active_heartrate', 'mean_bmi', 'mean_vo2']]\nX_4 = ht_agg_pandas_df[['mean_active_heartrate', 'mean_bmi', 'mean_vo2', 'mean_resting_heartrate']]\n\nle = LabelEncoder()\nlifestyle = ht_agg_pandas_df['lifestyle']\nle.fit(lifestyle)\ny = le.transform(lifestyle)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"09873abe-9fd6-4e3e-80b6-4928d0d2c790"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Framing a Business Problem\n\nOver the next few labs, we will use supervised machine learning\nto answer a new business question:\n\n> Given a users fitness profile, can we predict the lifestyle of a user?\n\nLike the regression problem we previously solved,\nour **inputs** will be fitness profile information. This is, however, a classification\nproblem and will have a different **output**, lifestyle."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"33e00a00-fe18-4f33-89a7-29a59bb649fc"}}},{"cell_type":"markdown","source":["### Perform the Train-Test Split\n\nNext, we will split one of our four subsets of feature data and our target data\ninto training and testing data."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4e247c70-6fa9-40bf-a3c7-f419406ffcb7"}}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n\nX_1_train, X_1_test, y_train, y_test = train_test_split(X_1, y)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"878c2b54-d31c-43aa-bc18-8fd960be17a7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Your Turn\n### Exercise 1: Perform the Train-Test Split\n\nPerform the train-test split on the remaining data subsets:\n1. use the helper function `train_test_split`\n1. split the following subsets:\n   - `X_2`, `X_3`, `X_4`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1c91d832-be18-4fd6-926f-fe1c0898c360"}}},{"cell_type":"code","source":["# ANSWER\nX_2_train, X_2_test, y_train, y_test = train_test_split(X_2, y)\nX_3_train, X_3_test, y_train, y_test = train_test_split(X_3, y)\nX_4_train, X_4_test, y_train, y_test = train_test_split(X_4, y)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"894c2709-a3b0-42ec-b5a4-f8fdf2514ed1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Exercise 2: Multi-Variable Decision Tree\n\nFit four multiple-variable logistic models, one for each datasubset."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"22c535e3-481f-48cb-80e8-b970b98a62dd"}}},{"cell_type":"code","source":["# ANSWER\nfrom sklearn.tree import DecisionTreeClassifier\ndt_1 = DecisionTreeClassifier()\ndt_2 = DecisionTreeClassifier()\ndt_3 = DecisionTreeClassifier()\ndt_4 = DecisionTreeClassifier()\n\ndt_1.fit(X_1_train, y_train)\ndt_2.fit(X_2_train, y_train)\ndt_3.fit(X_3_train, y_train)\ndt_4.fit(X_4_train, y_train)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bad9c4dd-dd98-4850-90f8-34403a9a3934"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[11]: DecisionTreeClassifier()</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[11]: DecisionTreeClassifier()</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Demonstration\n###Evaluate a Multi-variable Model using accuracy and a confusion matrix\n\nFinally, we evaulate our models. We do so using the accuracy metric and a confusion matrix.\n\nTo use these metrics, we need to\n1. generate a vector of precictions using `estimator.predict()`\n1. pass actual and predicted values to the metric as `metric(actual, predicted)`\n1. do this for both the training and testing data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f215c746-3c5d-4eaa-b487-86686852a2a7"}}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, confusion_matrix\n\ny_train_1_predicted = dt_1.predict(X_1_train)\ny_test_1_predicted = dt_1.predict(X_1_test)\n\nprint(\"training accuracy: \", accuracy_score(y_train, y_train_1_predicted))\nprint(\"test accuracy:     \", accuracy_score(y_test, y_test_1_predicted))\nprint(\"training confusion matrix\")\nprint(confusion_matrix(y_train, y_train_1_predicted))\nprint(\"\")\nprint(\"test confusion matrix\")\nprint(confusion_matrix(y_test, y_test_1_predicted))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"01e2ef0b-feff-4a00-9da9-b9ea7104b47e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">training accuracy:  1.0\ntest accuracy:      0.2866666666666667\ntraining confusion matrix\n[[637   0   0   0]\n [  0 801   0   0]\n [  0   0 245   0]\n [  0   0   0 567]]\n\ntest confusion matrix\n[[59 74 30 59]\n [66 99 43 55]\n [20 20 11 16]\n [51 81 20 46]]\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">training accuracy:  1.0\ntest accuracy:      0.2866666666666667\ntraining confusion matrix\n[[637   0   0   0]\n [  0 801   0   0]\n [  0   0 245   0]\n [  0   0   0 567]]\n\ntest confusion matrix\n[[59 74 30 59]\n [66 99 43 55]\n [20 20 11 16]\n [51 81 20 46]]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Question**: What do you notice about the results?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4fd9c439-0ce3-443b-a5b1-bca948d385e3"}}},{"cell_type":"markdown","source":["### Exercise 3: Generate Predictions\n1. use the following subset splits:\n   - `X_1_test`, `X_2_test`, `X_3_test`, `X_4_test`\n   - `X_1_train`, `X_2_train`, `X_3_train`, `X_4_train`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f51baa2b-2cf1-4a7f-8325-f85408c5204c"}}},{"cell_type":"code","source":["# ANSWER\ny_train_1_predicted = dt_1.predict(X_1_train)\ny_test_1_predicted = dt_1.predict(X_1_test)\ny_train_2_predicted = dt_2.predict(X_2_train)\ny_test_2_predicted = dt_2.predict(X_2_test)\ny_train_3_predicted = dt_3.predict(X_3_train)\ny_test_3_predicted = dt_3.predict(X_3_test)\ny_train_4_predicted = dt_4.predict(X_4_train)\ny_test_4_predicted = dt_4.predict(X_4_test)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bb0332ea-9fe5-4384-b2ed-a81c952f3b66"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Exercise 4: Evaluate Our Models\n\n1. Use the `accuracy_score` and `confusion_matrix` metrics\n1. don't forget to take the square root of the mean squared error\n1. use the following subset splits:\n   - `X_2_test`, `X_3_test`, `X_4_test`\n   - `X_2_train`, `X_3_train`, `X_4_train`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"925dd64f-b359-4865-89bd-e23e2a4682dd"}}},{"cell_type":"code","source":["# ANSWER\ntrain_1_accuracy = accuracy_score(y_train, y_train_1_predicted)\ntrain_1_conf_mat = confusion_matrix(y_train, y_train_1_predicted)\ntest_1_accuracy = accuracy_score(y_test, y_test_1_predicted)\ntest_1_conf_mat = confusion_matrix(y_test, y_test_1_predicted)\n\ntrain_2_accuracy = accuracy_score(y_train, y_train_2_predicted)\ntrain_2_conf_mat = confusion_matrix(y_train, y_train_2_predicted)\ntest_2_accuracy = accuracy_score(y_test, y_test_2_predicted)\ntest_2_conf_mat = confusion_matrix(y_test, y_test_2_predicted)\n\ntrain_3_accuracy = accuracy_score(y_train, y_train_3_predicted)\ntrain_3_conf_mat = confusion_matrix(y_train, y_train_3_predicted)\ntest_3_accuracy = accuracy_score(y_test, y_test_3_predicted)\ntest_3_conf_mat = confusion_matrix(y_test, y_test_3_predicted)\n\ntrain_4_accuracy = accuracy_score(y_train, y_train_4_predicted)\ntrain_4_conf_mat = confusion_matrix(y_train, y_train_4_predicted)\ntest_4_accuracy = accuracy_score(y_test, y_test_4_predicted)\ntest_4_conf_mat = confusion_matrix(y_test, y_test_4_predicted)\n\nprint(\"model 1: training accuracy: \", train_1_accuracy)\nprint(\"model 1: training confusion matrix: \")\nprint(train_1_conf_mat)\nprint(\" \")\nprint(\"model 1: test accuracy:     \", test_1_accuracy)\nprint(\"model 1: test confusion matrix:     \")\nprint(test_1_conf_mat)\nprint(\" \")\nprint(\"model 2: training accuracy: \", train_2_accuracy)\nprint(\"model 2: training confusion matrix: \")\nprint(train_2_conf_mat)\nprint(\" \")\nprint(\"model 2: test accuracy:     \", test_2_accuracy)\nprint(\"model 2: test confusion matrix:     \")\nprint(test_2_conf_mat)\nprint(\" \")\nprint(\"model 3: training accuracy: \", train_3_accuracy)\nprint(\"model 3: training confusion matrix: \")\nprint(train_3_conf_mat)\nprint(\" \")\nprint(\"model 3: test accuracy:     \", test_3_accuracy)\nprint(\"model 3: test confusion matrix:     \")\nprint(test_3_conf_mat)\nprint(\" \")\nprint(\"model 4: training accuracy: \", train_4_accuracy)\nprint(\"model 4: training confusion matrix: \")\nprint(train_4_conf_mat)\nprint(\" \")\nprint(\"model 4: test accuracy:     \", test_4_accuracy)\nprint(\"model 4: test confusion matrix:     \")\nprint(test_4_conf_mat)\nprint(\" \")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d006ca16-893e-46bb-9f1a-f38723675696"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">model 1: training accuracy:  1.0\nmodel 1: training confusion matrix: \n[[637   0   0   0]\n [  0 801   0   0]\n [  0   0 245   0]\n [  0   0   0 567]]\n \nmodel 1: test accuracy:      0.2866666666666667\nmodel 1: test confusion matrix:     \n[[59 74 30 59]\n [66 99 43 55]\n [20 20 11 16]\n [51 81 20 46]]\n \nmodel 2: training accuracy:  1.0\nmodel 2: training confusion matrix: \n[[637   0   0   0]\n [  0 801   0   0]\n [  0   0 245   0]\n [  0   0   0 567]]\n \nmodel 2: test accuracy:      0.2826666666666667\nmodel 2: test confusion matrix:     \n[[70 73 29 50]\n [65 90 32 76]\n [15 27  7 18]\n [63 69 21 45]]\n \nmodel 3: training accuracy:  1.0\nmodel 3: training confusion matrix: \n[[637   0   0   0]\n [  0 801   0   0]\n [  0   0 245   0]\n [  0   0   0 567]]\n \nmodel 3: test accuracy:      0.30933333333333335\nmodel 3: test confusion matrix:     \n[[ 76  75  18  53]\n [ 62 103  36  62]\n [ 17  27   9  14]\n [ 56  73  25  44]]\n \nmodel 4: training accuracy:  1.0\nmodel 4: training confusion matrix: \n[[637   0   0   0]\n [  0 801   0   0]\n [  0   0 245   0]\n [  0   0   0 567]]\n \nmodel 4: test accuracy:      0.564\nmodel 4: test confusion matrix:     \n[[113  63   5  41]\n [ 63 188   0  12]\n [  2   0  31  34]\n [ 44  11  52  91]]\n \n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">model 1: training accuracy:  1.0\nmodel 1: training confusion matrix: \n[[637   0   0   0]\n [  0 801   0   0]\n [  0   0 245   0]\n [  0   0   0 567]]\n \nmodel 1: test accuracy:      0.2866666666666667\nmodel 1: test confusion matrix:     \n[[59 74 30 59]\n [66 99 43 55]\n [20 20 11 16]\n [51 81 20 46]]\n \nmodel 2: training accuracy:  1.0\nmodel 2: training confusion matrix: \n[[637   0   0   0]\n [  0 801   0   0]\n [  0   0 245   0]\n [  0   0   0 567]]\n \nmodel 2: test accuracy:      0.2826666666666667\nmodel 2: test confusion matrix:     \n[[70 73 29 50]\n [65 90 32 76]\n [15 27  7 18]\n [63 69 21 45]]\n \nmodel 3: training accuracy:  1.0\nmodel 3: training confusion matrix: \n[[637   0   0   0]\n [  0 801   0   0]\n [  0   0 245   0]\n [  0   0   0 567]]\n \nmodel 3: test accuracy:      0.30933333333333335\nmodel 3: test confusion matrix:     \n[[ 76  75  18  53]\n [ 62 103  36  62]\n [ 17  27   9  14]\n [ 56  73  25  44]]\n \nmodel 4: training accuracy:  1.0\nmodel 4: training confusion matrix: \n[[637   0   0   0]\n [  0 801   0   0]\n [  0   0 245   0]\n [  0   0   0 567]]\n \nmodel 4: test accuracy:      0.564\nmodel 4: test confusion matrix:     \n[[113  63   5  41]\n [ 63 188   0  12]\n [  2   0  31  34]\n [ 44  11  52  91]]\n \n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Question**: Which of these models is the best at predicting lifestyle?\n\n**Question**: Do any of the models show signs of overfitting?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"27a6ca8e-4baa-45e2-a80b-7e4842dda370"}}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2021 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a64034f9-63a7-473a-a90d-1d50b0029598"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"5.4.1 Lab - Decision Tree Lab","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3165647092658847}},"nbformat":4,"nbformat_minor":0}
